{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_spatial_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJQ_Awh1LK-9"
      },
      "source": [
        "!pip install timm > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfJhYobXafa8"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import random\n",
        "import gc"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB4NNY7Yawfs"
      },
      "source": [
        "def get_activation(activ_name: str = 'relu'):\n",
        "  \"\"\" this function will return the activation function \"\"\"\n",
        "\n",
        "  act_dict = {\n",
        "      \"relu\": nn.ReLU(inplace=True),\n",
        "        \"tanh\": nn.Tanh(),\n",
        "        \"sigmoid\": nn.Sigmoid(),\n",
        "        \"identity\": nn.Identity(),\n",
        "  }\n",
        "\n",
        "  if activ_name in act_dict:\n",
        "    return act_dict[activ_name]\n",
        "  else:\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9O8RyBjbSrM"
      },
      "source": [
        "class Conv2DBNActiv(nn.Module):\n",
        "  \"\"\" Conv2d -> (BN ->) -> Activation \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               in_channels : int,\n",
        "               out_channels : int,\n",
        "               kernel_size : int,\n",
        "               stride : int = 1,\n",
        "               padding : int = 0,\n",
        "               bias : bool = False,\n",
        "               use_bn : bool = True,\n",
        "               activ : str = 'relu',\n",
        "               ):\n",
        "    super(Conv2DBNActiv, self).__init__()\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(\n",
        "            in_channels, out_channels,\n",
        "            kernel_size, stride, padding, bias=bias))\n",
        "    if use_bn:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "    \n",
        "    layers.append(get_activation(activ))\n",
        "    self.layers = nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlIZZxgDcyLP"
      },
      "source": [
        "class SpatialAttentionBlock(nn.Module):\n",
        "  \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "        self, in_channels: int,\n",
        "        out_channels_list,\n",
        "    ):\n",
        "    super(SpatialAttentionBlock, self).__init__()\n",
        "    self.n_layers = len(out_channels_list)\n",
        "    channels_list = [in_channels] + out_channels_list\n",
        "    assert self.n_layers > 0\n",
        "    assert channels_list[-1] == 1\n",
        "\n",
        "    for i in range(self.n_layers - 1):\n",
        "      in_chs, out_chs = channels_list[i : i + 2]\n",
        "      layer = Conv2DBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
        "      setattr(self, f\"conv{i + 1}\" , layer)\n",
        "    \n",
        "    in_chs, out_chs = channels_list[-2:]\n",
        "    layer = Conv2DBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
        "    setattr(self, f\"conv{self.n_layers}\", layer)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = x\n",
        "    for i in range(self.n_layers):\n",
        "        h = getattr(self, f\"conv{i + 1}\")(h)\n",
        "        \n",
        "    h = h * x\n",
        "    return h"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnuUK3FselR4",
        "outputId": "504b754c-cb8a-4278-dc29-b095bd299566"
      },
      "source": [
        "SpatialAttentionBlock(3, [64, 32, 16, 1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpatialAttentionBlock(\n",
              "  (conv1): Conv2DBNActiv(\n",
              "    (layers): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv2): Conv2DBNActiv(\n",
              "    (layers): Sequential(\n",
              "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv3): Conv2DBNActiv(\n",
              "    (layers): Sequential(\n",
              "      (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv4): Conv2DBNActiv(\n",
              "    (layers): Sequential(\n",
              "      (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z68ALRIJeozH"
      },
      "source": [
        "class CustomModel(nn.Module):\n",
        "  def __init__(\n",
        "        self, \n",
        "        base_name: str = 'resnet18', \n",
        "        out_dim: int = 2, \n",
        "        pretrained = False,\n",
        "    ):\n",
        "        self.base_name = base_name\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        #loading the base model\n",
        "        base_model = timm.create_model(base_name, pretrained=pretrained)\n",
        "        in_features = base_model.num_features\n",
        "\n",
        "        # remove global pooling and head classifier\n",
        "        # base_model.reset_classifier(0)\n",
        "        base_model.reset_classifier(0, '')\n",
        "\n",
        "        self.backbone = base_model\n",
        "\n",
        "        self.head_fc = nn.Sequential(\n",
        "            SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
        "            nn.AdaptiveAvgPool2d(output_size=1),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features, out_dim))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    h = self.backbone(x)\n",
        "    h = self.head_fc(h)\n",
        "    return h"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "susEQ14ggkjY",
        "outputId": "b627572d-1d25-4ee2-ad8a-05b7f03ed387"
      },
      "source": [
        "model = CustomModel()\n",
        "model"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (act1): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d (pool_type=, flatten=Identity())\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (head_fc): Sequential(\n",
              "    (0): SpatialAttentionBlock(\n",
              "      (conv1): Conv2DBNActiv(\n",
              "        (layers): Sequential(\n",
              "          (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2DBNActiv(\n",
              "        (layers): Sequential(\n",
              "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv3): Conv2DBNActiv(\n",
              "        (layers): Sequential(\n",
              "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv4): Conv2DBNActiv(\n",
              "        (layers): Sequential(\n",
              "          (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): AdaptiveAvgPool2d(output_size=1)\n",
              "    (2): Flatten(start_dim=1, end_dim=-1)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQbHi1Fxgrh_",
        "outputId": "4ce0c405-6efd-4f96-82ab-6ff7a594b312"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "sample_image = torch.rand(1, 3, 512, 512)\n",
        "with torch.no_grad():\n",
        "  y = model(sample_image)\n",
        "\n",
        "print(\"[forward test]\")\n",
        "print(\"input:\\t{}\\noutput:\\t{}\".format(sample_image.shape, y.shape))\n",
        "\n",
        "del model ; del y ; del sample_image\n",
        "gc.collect()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[forward test]\n",
            "input:\ttorch.Size([1, 3, 512, 512])\n",
            "output:\ttorch.Size([1, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "917"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}